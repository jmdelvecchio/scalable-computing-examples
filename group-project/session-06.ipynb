{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the libraries we need\n",
    "import os\n",
    "\n",
    "import parsl\n",
    "from parsl import python_app\n",
    "from parsl.config import Config\n",
    "from parsl.channels import LocalChannel\n",
    "from parsl.executors import HighThroughputExecutor\n",
    "from parsl.providers import LocalProvider\n",
    "\n",
    "# helpers\n",
    "from grouputils import initialize_stager\n",
    "from grouputils import plot_tiles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "The first step in our workflow is to \"stage\" our data. Staging the data encompasses the following pre-processing tasks:\n",
    "\n",
    "- simplify the polygons \n",
    "- set an input CRS if one is missing\n",
    "- reproject the data when required\n",
    "- add additional properties to each polygon, including: the centroid x and y\n",
    "  coordinates, the area, a unique ID, and the name of the file that the\n",
    "  polygon originated from\n",
    "- break each input file into [standardized tiles](https://docs.opengeospatial.org/is/17-083r2/17-083r2.html), and save them to disk.\n",
    "\n",
    "Here is a diagram showing what the most important step, the last one, looks like.\n",
    "\n",
    "![](https://raw.githubusercontent.com/PermafrostDiscoveryGateway/viz-staging/develop/docs/images/staging_tldr.png)\n",
    "\n",
    "We will use some methods from the `pdgstaging` library to stage our tiles. The first step, is to initalize the `TileStager`. The `TileStager` is a class with a method `stage`, which works on a single vector file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initalize the stager\n",
    "\n",
    "Fist we need to use the `initialize_stager` function to instantiate the `TileStager` object. The only argument to this function is `dir_input`, the directory of input data.\n",
    "\n",
    "Input vector files are located **in `/home/shares/example-pdg-data`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute the initialize_stager function with the appropriate arguments\n",
    "# save the result to a variable called iwp_stager\n",
    "iwp_stager = initialize_stager(\"/home/shares/example-pdg-data\")\n",
    "# this is a helper function \"from grouputils import initialize_stager\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to explore the `iwp_stager` object in any way you like.\n",
    "\n",
    "Next let's use it to get a list of files to stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_stage = iwp_stager.tiles.get_filenames_from_dir('input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage one file\n",
    "\n",
    "Here is an example of how to run the stager on one file. We use the `stage` method on the `iwp_stager` object, with a path to a file as the argument to the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_file = files_to_stage[0]\n",
    "iwp_stager.stage(example_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on how long staging one file took, estimate how long that would take to stage all the input files that we have in this example, serially. How long would it take if we had 100 files? 1000?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate computation time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these example data, the amount of time it takes is not super high. But as the number of files gets bigger, things get out of hand quickly. Luckily for us, this problem is pleasingly parallel. The staging of each file is completely independent of the others. So, let's set this up as a `parsl` workflow using the skills we learned in Section 4. \n",
    "\n",
    "Just to get a sense of what happened, let's plot the result of our test staging effort using a `plot_tiles` helper we wrote for this activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tiles(iwp_stager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's remove the files we just created (including the staging summary csv file) to prepare to run this over all of the files. If we don't do this polygons will get appended to the staged files which will result in duplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(f'rm -rf {iwp_stager.config.get(\"dir_staged\")}')\n",
    "os.system(f'rm {iwp_stager.config.get(\"filename_staging_summary\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Staging in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First set up the configuration for `parsl` using `config`, and a `HighThroughputExecutor`. For the executor, set the `max_workers` to 32, and the `max_blocks` for the `provider` to 1. This will spread our work over 32 processes on the server. Make sure you pass the bash command you use to invoke your virtual environment to the `worker_init` argument as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<parsl.dataflow.dflow.DataFlowKernel at 0x7f12a3146550>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activate_env = 'workon scomp'\n",
    "\n",
    "htex_config = Config(\n",
    "  executors=[\n",
    "      HighThroughputExecutor(\n",
    "            max_workers=32,\n",
    "            provider=LocalProvider(\n",
    "                worker_init=activate_env\n",
    "                # Do this shell thing\n",
    "        )\n",
    "      )\n",
    "  ]\n",
    ")\n",
    "parsl.clear()\n",
    "# Clear any previous work\n",
    "parsl.load(htex_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, set up your Parsl app to run the `stage` method in parallel. You'll need to pass as arguments to the app function the `TileStager` instance we created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a Parsl app that uses the stage method\n",
    "# You want python_app to operate only on a single unit in parallel, not the whole function\n",
    "\n",
    "@python_app\n",
    "def stage_parsl(file, iwp_stager):\n",
    "    # pass stage_parsl a single file rather than a list\n",
    "    # for reasons stated above\n",
    "    iwp_stager.stage(file)\n",
    "    # 'staged' is a None rn\n",
    "    return file\n",
    "\n",
    "app_futures = stage_parsl(files_to_stage[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [84], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m     app_future \u001b[38;5;241m=\u001b[39m stage_parsl(path, iwp_stager)\n\u001b[1;32m      4\u001b[0m     app_futures\u001b[38;5;241m.\u001b[39mappend(app_future)\n\u001b[0;32m----> 6\u001b[0m done \u001b[38;5;241m=\u001b[39m [future\u001b[38;5;241m.\u001b[39mresult() \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m app_futures]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(done)\n",
      "Cell \u001b[0;32mIn [84], line 6\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m     app_future \u001b[38;5;241m=\u001b[39m stage_parsl(path, iwp_stager)\n\u001b[1;32m      4\u001b[0m     app_futures\u001b[38;5;241m.\u001b[39mappend(app_future)\n\u001b[0;32m----> 6\u001b[0m done \u001b[38;5;241m=\u001b[39m [\u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m app_futures]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(done)\n",
      "File \u001b[0;32m/usr/lib/python3.9/concurrent/futures/_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 441\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    443\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    444\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/usr/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "app_futures = []\n",
    "for path in files_to_stage:\n",
    "    app_future = stage_parsl(path, iwp_stager)\n",
    "    app_futures.append(app_future)\n",
    "\n",
    "done = [future.result() for future in app_futures]\n",
    "print(done)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So fam, this originally didn't work because AppFuture can't be iterated. Jeanette's solution works because there is only a single future result being created rather than what we tried to do which was make a big future and then try to break it apart after.\n",
    "\n",
    "Moreover, `@python_app` can only be assigned to a function with a SINGLE input. You write a script that iterates on a parsl function, you can't write a parsl function that takes a list etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't forget to shutdown and clear your executor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check out the `plot_tiles` result again (which will only plot the first 92 of our tiled files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tiles(iwp_stager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "This process took the original 35 files, ranging in size from 20MB to 500MB (6 GB total), and tiled them into arond 2200 files, and if you set up your executor like we described, it should have taken around 15 minutes. \n",
    "\n",
    "Discuss in your groups whether you suspect this process is CPU bound, I/O bound, memory bound, or network bound. How would you figure it out for sure? Why would you want to know?\n",
    "\n",
    "### Answer\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('scomp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3bc86895b5d8569f33588bfbb1475393b4e3b52b49eb441663b259ecef6692f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
