{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 11: Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# For parallel processing\n",
    "import parsl\n",
    "import parsl\n",
    "from parsl import python_app\n",
    "from parsl.config import Config\n",
    "from parsl.channels import LocalChannel\n",
    "from parsl.executors import HighThroughputExecutor\n",
    "from parsl.providers import LocalProvider\n",
    "\n",
    "# helpers\n",
    "from grouputils import initialize_rasterizer\n",
    "from grouputils import plot_tiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "![](https://raw.githubusercontent.com/PermafrostDiscoveryGateway/viz-raster/develop/docs/images/raster_tldr.png)\n",
    "\n",
    "Today, we will take the regularly gridded staged data from yesterday and create rasters from the vector data (left side of diagram above). Each pixel of the raster will contain a stasticic calculated based on the underlying vector data for that pixel.\n",
    "\n",
    "The two statistics we calculate are:\n",
    "\n",
    "- number of IWP per pixel\n",
    "- proportion of pixel covered by IWP\n",
    "\n",
    "Similar to the `TileStager` from the first step of the group project, in this step we will use a `RasterTiler` class, which we initialize using `initialize_rasterizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "iwp_rasterizer = initialize_rasterizer(\"/home/shares/example-pdg-data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's have a look at the data we need to rasterize first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2249 files to rasterize.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "staged_paths = iwp_rasterizer.tiles.get_filenames_from_dir('staged')\n",
    "print(len(staged_paths), \"files to rasterize.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `rasterize_vector` method on our `RasterTiler` class object, and pass it the first file in our list of staged files to rasterize just one file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tile(x=942, y=1076, z=13)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iwp_rasterizer.rasterize_vector(staged_paths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This went pretty quickly, but with thousands of files, it would still be beneficial to paralleize. Estimate the length of time it would take to process the files in series below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(3 * len(staged_paths)/60, \"minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rasterize in Parallel\n",
    "\n",
    "Given what you know about the limits of parallelization, discuss in your group whether you think this problem is:\n",
    "\n",
    "- cpu-bound\n",
    "- memory-bound\n",
    "- I/O-bound\n",
    "- network-bound\n",
    "\n",
    "How does it compare to the parallelization task from yesterday?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of parallelizing this step over all 2000 files, we will instead process the data in batches of files. Below is a function we can use to make batches of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because rasterization is relatively quick, we want each parsl \"task\" to process a batch of tiles.\n",
    "def make_batch(items, batch_size):\n",
    "    # Create batches of a given size from a list of items.\n",
    "    return [items[i:i + batch_size] for i in range(0, len(items), batch_size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `make_batch` function to make batches of 10 items each of our staged data (`staged_paths`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make batches of 10 files\n",
    "batch_size = 10\n",
    "batches = make_batch(staged_paths, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, set up your Parsl executor again, with `max_workers` set at 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<parsl.dataflow.dflow.DataFlowKernel at 0x7f880fdd31f0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up Parsl executor\n",
    "activate_env = 'workon scomp'\n",
    "htex_local = Config(\n",
    "    executors=[\n",
    "        HighThroughputExecutor(\n",
    "            max_workers=32,\n",
    "            provider=LocalProvider(\n",
    "                worker_init=activate_env\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "parsl.clear()\n",
    "parsl.load(htex_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, set up your Parsl app to run the `rasterize_vector` method in parallel. Remember that Parsl apps cannot rely on global variables or package imports, so you'll need to make sure to pass the app all of the variables it needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a Parsl app that uses the rasterize_vectors method\n",
    "@python_app\n",
    "def rasterize(staged_paths, rasterizer):\n",
    "    # Rasterize a batch of vector files\n",
    "    return rasterizer.rasterize_vectors(staged_paths, make_parents=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, execute the app in parallel over all of the batches of files you created previously. Don't forget to add a line to shut down the executor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m     app_futures\u001b[38;5;241m.\u001b[39mappend(app_future)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Don't continue to print message until all tiles have been rasterized\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m done \u001b[38;5;241m=\u001b[39m [app_future\u001b[38;5;241m.\u001b[39mresult() \u001b[38;5;28;01mfor\u001b[39;00m app_future \u001b[38;5;129;01min\u001b[39;00m app_futures]\n\u001b[1;32m     10\u001b[0m htex_local\u001b[38;5;241m.\u001b[39mexecutors[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshutdown()\n\u001b[1;32m     11\u001b[0m parsl\u001b[38;5;241m.\u001b[39mclear()\n",
      "Cell \u001b[0;32mIn [13], line 8\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m     app_futures\u001b[38;5;241m.\u001b[39mappend(app_future)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Don't continue to print message until all tiles have been rasterized\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m done \u001b[38;5;241m=\u001b[39m [\u001b[43mapp_future\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m app_future \u001b[38;5;129;01min\u001b[39;00m app_futures]\n\u001b[1;32m     10\u001b[0m htex_local\u001b[38;5;241m.\u001b[39mexecutors[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshutdown()\n\u001b[1;32m     11\u001b[0m parsl\u001b[38;5;241m.\u001b[39mclear()\n",
      "File \u001b[0;32m/usr/lib/python3.9/concurrent/futures/_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 441\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    443\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    444\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/usr/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Rasterize the batches in parallel\n",
    "app_futures = []\n",
    "for batch in batches[0:2]:\n",
    "    app_future = rasterize(batch, iwp_rasterizer)\n",
    "    app_futures.append(app_future)\n",
    "\n",
    "# Don't continue to print message until all tiles have been rasterized\n",
    "done = [app_future.result() for app_future in app_futures]\n",
    "\n",
    "htex_local.executors[0].shutdown()\n",
    "parsl.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you set your executor up correctly, this should have finished in around 18 minutes. Check to make sure that you have the same number of GeoTIFF files as we do staged vector tiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geotiff_paths = iwp_rasterizer.tiles.get_filenames_from_dir('geotiff')\n",
    "len(geotiff_paths) == len(staged_paths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "Thinking back to the group project yesterday, how would you test whether this problem is CPU or I/O bound? One option would be to test whether adding more CPU decreases your computation time. Set up a test on a subset of the staged files (the first 500 is fine) and time the process at different `max_workers`. To make sure you don't overload the server, do not exceed 32 workers in your tests.\n",
    "\n",
    "### Results\n",
    "\n",
    "Here are the results for three sets of tests where the `max_workers` was increased all the way to 88. We also varied the number of files in each batch, which effectively alters the degree of parallelism in our code. The result is a figure which looks remarkably like Amdahl's Law!\n",
    "\n",
    "![](../images/parallel-performance.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('scomp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3bc86895b5d8569f33588bfbb1475393b4e3b52b49eb441663b259ecef6692f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
