{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the libraries we need\n",
    "import os\n",
    "\n",
    "import parsl\n",
    "from parsl import python_app\n",
    "from parsl.config import Config\n",
    "from parsl.channels import LocalChannel\n",
    "from parsl.executors import HighThroughputExecutor\n",
    "from parsl.providers import LocalProvider\n",
    "\n",
    "# helpers\n",
    "from grouputils import initialize_stager\n",
    "from grouputils import plot_tiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "The first step in our workflow is to \"stage\" our data. Staging the data encompasses the following pre-processing tasks:\n",
    "\n",
    "- simplify the polygons \n",
    "- set an input CRS if one is missing\n",
    "- reproject the data when required\n",
    "- add additional properties to each polygon, including: the centroid x and y\n",
    "  coordinates, the area, a unique ID, and the name of the file that the\n",
    "  polygon originated from\n",
    "- break each input file into [standardized tiles](https://docs.opengeospatial.org/is/17-083r2/17-083r2.html), and save them to disk.\n",
    "\n",
    "Here is a diagram showing what the most important step, the last one, looks like.\n",
    "\n",
    "![](https://raw.githubusercontent.com/PermafrostDiscoveryGateway/viz-staging/develop/docs/images/staging_tldr.png)\n",
    "\n",
    "We will use some methods from the `pdgstaging` library to stage our tiles. The first step, is to initalize the `TileStager`. The `TileStager` is a class with methods `stage`, which works on a single vector file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initalize the stager\n",
    "\n",
    "Fist we need to use the `initialize_stager` function to instantiate the `TileStager` object. The arguments to this function are `dir_input`, the directory of input vector files, and `dir_staged`, the directory of output vector files.\n",
    "\n",
    "Input vector files are located **in `/home/shares/example-pdg-data`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute the initialize_stager function with the appropriate arguments\n",
    "# save the result to a variable called iwp_stager\n",
    "iwp_stager = initialize_stager(\"/home/shares/example-pdg-data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to explore the `iwp_stager` object in any way you like.\n",
    "\n",
    "Next let's use it to get a list of files to stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_stage = iwp_stager.tiles.get_filenames_from_dir('input')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage one file\n",
    "\n",
    "Here is an example of how to run the stager on one file. We use the `stage` method on the `iwp_stager` object, with a path to a file as the argument to the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_file = files_to_stage[0]\n",
    "iwp_stager.stage(example_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on how long staging one file took, estimate how long that would take to stage all the input files that we have in this example, serially. How long would it take if we had 100 files? 1000?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{87 * len(files_to_stage)/60} minutes for examples, {round(87*100/60/60)} hours for 100 files, {round(87*1000/60/60)} hours for 1000 files')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these example data, the amount of time it takes is not super high. But as the number of files gets bigger, things get out of hand quickly. Luckily for us, this problem is pleasingly parallel. The staging of each file is completely independent of the others. So, let's set this up as a `parsl` workflow using the skills we learned in Section 4. \n",
    "\n",
    "Just to get a sense of what happened, let's plot the result of our test staging effort using a `plot_tiles` helper we wrote for this activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tiles(iwp_stager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's remove the files we just created (including the staging summary csv file) to prepare to run this over all of the files. If we don't do this polygons will get appended to the staged files which will result in duplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(f'rm -rf {iwp_stager.config.get(\"dir_staged\")}')\n",
    "os.system(f'rm {iwp_stager.config.get(\"filename_staging_summary\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Staging in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First set up the configuration for `parsl` using `config`, and a `HighThroughputExecutor`. For the executor, set the `max_workers` to 32. This will spread our work over 32 processes on the server. Make sure you pass the bash command you use to invoke your virtual environment as a string to the `provider` function as the `worker_init` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# htex_config = config(\n",
    "#   executors=[\n",
    "#       HighThroughputExecutor(\n",
    "#           ..., \n",
    "#           provider = LocalProvider(...)\n",
    "#       )\n",
    "#   ]\n",
    "# )\n",
    "activate_env = 'workon scomp'\n",
    "htex_local = Config(\n",
    "    executors=[\n",
    "        HighThroughputExecutor(\n",
    "            max_workers=32,\n",
    "            provider=LocalProvider(\n",
    "                worker_init=activate_env\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "parsl.clear()\n",
    "parsl.load(htex_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, set up your Parsl app to run the `stage` method in parallel. You'll need to pass as arguments to the app function and the `TileStager` instance we created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a Parsl app that uses the stage method\n",
    "@python_app\n",
    "def stage_file(path, stager):\n",
    "    stager.stage(path)\n",
    "    return path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, execute the app in parallel over all of the `files_to_stage`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_futures = []\n",
    "for path in files_to_stage:\n",
    "    app_future = stage_file(path, iwp_stager)\n",
    "    app_futures.append(app_future)\n",
    "\n",
    "# By getting the `result()` of each app future, this block won't continue to \n",
    "# the print statement until all the files are staged.\n",
    "done = [app_future.result() for app_future in app_futures]\n",
    "\n",
    "htex_local.executors[0].shutdown()\n",
    "parsl.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check out the `plot_tiles` result again (which will only plot the first 92 of our tiled files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tiles(iwp_stager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "This process took the original 35 files, ranging in size from 20MB to 500MB (6 GB total), and tiled them into arond 2200 files, and if you set up your executor like we described, it should have taken around 15 minutes. \n",
    "\n",
    "Discuss in your groups whether you suspect this process is CPU bound, I/O bound, memory bound, or network bound. How would you figure it out for sure? Why would you want to know?\n",
    "\n",
    "### Answer\n",
    "\n",
    "This process seems to be I/O bound. We can rule out memory bound, since the total data to process is 6GB and the memory on our server is much greater than that (126 GB). It is also not network bound, since all of the data are local to our process, and don't need to be transferred at all.\n",
    "\n",
    "This leaves CPU or I/O bound. One way to test whether the process is CPU bound is to see if adding more workers (CPU power) decreases the computation time. Spoiler: it doesn't! If you increase the number of workers in the executor, the process still takes around 15 minutes to finish. Additionally, the CPU load and CPU utilization remain approximately the same. To check out the CPU load during a process (amongst other stats) the command line `dstat` is helpful. I like `dstat -a --load` to look at CPU load specifically.\n",
    "\n",
    "So now we are leaning towards I/O bound, which makes sense, given that we are reading in some decently sized files, and then having to write out a whole bunch of files. How can we confirm? The commandline tool `iostat` (`iostat -kx 1`) will show the percentage of CPU time during which I/O requests are sent in the `%util` column. A high percentage here is a potential indicator that your process is I/O limited. Other stats to look at are the disk latency and request wait time, both of which are indicators that the process is waiting a while for things to finish writing to disk. The way to test all this, of course, would be to run the process on a machine with a faster disk to see if you can decrease your process time.\n",
    "\n",
    "As for why we would want to know this, if we wanted to speed up our process, and it is I/O bound, throwing more CPU at it will not make it faster (as just discussed). So it is important to know the nature of the problem, so that you can address it appropriately."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('scomp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0030ed2ed4c0609037967981d5426019e14a913516344490dbc8ffbbe92f86b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
