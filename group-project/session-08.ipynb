{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the libraries we need\n",
    "import os\n",
    "\n",
    "import parsl\n",
    "from parsl import python_app\n",
    "from parsl.config import Config\n",
    "from parsl.channels import LocalChannel\n",
    "from parsl.executors import HighThroughputExecutor\n",
    "from parsl.providers import LocalProvider\n",
    "\n",
    "# helpers\n",
    "from grouputils import initialize_stager\n",
    "from grouputils import plot_tiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "The first step in our workflow is to \"stage\" our data. Staging the data encompasses the following pre-processing tasks:\n",
    "\n",
    "- simplify the polygons \n",
    "- set an input CRS if one is missing\n",
    "- reproject the data when required\n",
    "- add additional properties to each polygon, including: the centroid x and y\n",
    "  coordinates, the area, a unique ID, and the name of the file that the\n",
    "  polygon originated from\n",
    "- break each input file into [standardized tiles](https://docs.opengeospatial.org/is/17-083r2/17-083r2.html), and save them to disk.\n",
    "\n",
    "Here is a diagram showing what the most important step, the last one, looks like.\n",
    "\n",
    "![](https://raw.githubusercontent.com/PermafrostDiscoveryGateway/viz-staging/develop/docs/images/staging_tldr.png)\n",
    "\n",
    "We will use some methods from the `pdgstaging` library to stage our tiles. The first step is to initalize the `TileStager`. The `TileStager` is a class with methods `stage`, which works on a single vector file, and `stage_all` which stages all vector files in a directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initalize the stager\n",
    "\n",
    "Fist we need to use the `initialize_stager` function to instantiate the `TileStager` object. The arguments to this function are `dir_input`, the directory of input vector files, and `dir_staged`, the directory of output vector files.\n",
    "\n",
    "Input vector files are located in `/home/jclark/example-data`, which everyone in the course can read from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute the initialize_stager function with the appropriate arguments\n",
    "# save the result to a variable called iwp_stager\n",
    "iwp_stager = initialize_stager(\"/home/jclark/example-data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to explore the `iwp_stager` object in any way you like.\n",
    "\n",
    "Next let's use it to get a list of files to stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_stage = iwp_stager.tiles.get_filenames_from_dir('input')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage one file\n",
    "\n",
    "Here is an example of how to run the stager on one file. We use the `stage` method on the `iwp_stager` object, with a path to a file as the argument to the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/jclark/scalable-computing-examples/group-project/session-08.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bincluded-crab.nceas.ucsb.edu/home/jclark/scalable-computing-examples/group-project/session-08.ipynb#ch0000007vscode-remote?line=0'>1</a>\u001b[0m example_file \u001b[39m=\u001b[39m files_to_stage[\u001b[39m0\u001b[39;49m]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bincluded-crab.nceas.ucsb.edu/home/jclark/scalable-computing-examples/group-project/session-08.ipynb#ch0000007vscode-remote?line=1'>2</a>\u001b[0m iwp_stager\u001b[39m.\u001b[39mstage(example_file)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "example_file = files_to_stage[0]\n",
    "iwp_stager.stage(example_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on how long staging one file took, estimate how long that would take to stage all the input files that we have in this example, serially. How long would it take if we had 100 files? 1000?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate duration here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these example data, the amount of time it takes is not super high. But as the number of files gets bigger, things get out of hand quickly. Luckily for us, this problem is pleasingly parallel. The staging of each file is completely independent of the others. So, let's set this up as a `parsl` workflow using the skills we learned in Section 4. \n",
    "\n",
    "Just to get a sense of what happened, let's plot the result of our test staging effort using a `plot_tiles` helper we wrote for this activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tiles(iwp_stager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's remove the files we just created (including the staging summary csv file) to prepare to run this over all of the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(f'rm -rf {iwp_stager.config.get(\"dir_staged\")}')\n",
    "os.system(f'rm {iwp_stager.config.get(\"filename_staging_summary\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Staging in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First set up the configuration for `parsl` using `config`. Make sure you pass the bash command you use to invoke your virtual environment to the `worker_init` argument as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# htex_config = config(...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, set up your Parsl app to run the `stage` method in parallel. Remember that Parsl apps cannot rely on global variables or package imports, so you'll need to make sure to pass the app all of the variables it needs (hint: one of them will be the `TileStager` instance we created earlier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a Parsl app that uses the stage method\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, execute the app in parallel over all of the `files_to_stage`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the parsl app over all of the files to stage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check out the `plot_tiles` result again (which will only plot the first 90 of our tiled files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tiles(iwp_stager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "If your group finishes early, explore any performance differences you find using a high throughput executor versus a threadpool executor. For more on `parsl` execution see [the docs](https://parsl.readthedocs.io/en/stable/userguide/execution.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('scomp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0030ed2ed4c0609037967981d5426019e14a913516344490dbc8ffbbe92f86b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
